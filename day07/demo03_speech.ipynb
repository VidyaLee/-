{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../ml_data/speeches/training\n",
      "['apple', 'banana', 'kiwi', 'lime', 'orange', 'peach', 'pineapple']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#语音识别\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import python_speech_features as sf\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as sm\n",
    "import os\n",
    "\n",
    "#检索directory目录下的所有文件，返回目录字典\n",
    "def search_files(directory):\n",
    "    objects={}\n",
    "    for curdir,subdirs,files in os.walk(directory):\n",
    "        print(curdir)\n",
    "        print(subdirs)\n",
    "        print(files) \n",
    "        break\n",
    "search_files('../ml_data/speeches/training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apple': ['../ml_data/speeches/training\\\\apple\\\\apple01.wav', '../ml_data/speeches/training\\\\apple\\\\apple02.wav', '../ml_data/speeches/training\\\\apple\\\\apple03.wav', '../ml_data/speeches/training\\\\apple\\\\apple04.wav', '../ml_data/speeches/training\\\\apple\\\\apple05.wav', '../ml_data/speeches/training\\\\apple\\\\apple06.wav', '../ml_data/speeches/training\\\\apple\\\\apple07.wav', '../ml_data/speeches/training\\\\apple\\\\apple08.wav', '../ml_data/speeches/training\\\\apple\\\\apple09.wav', '../ml_data/speeches/training\\\\apple\\\\apple10.wav', '../ml_data/speeches/training\\\\apple\\\\apple11.wav', '../ml_data/speeches/training\\\\apple\\\\apple12.wav', '../ml_data/speeches/training\\\\apple\\\\apple13.wav', '../ml_data/speeches/training\\\\apple\\\\apple14.wav'], 'banana': ['../ml_data/speeches/training\\\\banana\\\\banana01.wav', '../ml_data/speeches/training\\\\banana\\\\banana02.wav', '../ml_data/speeches/training\\\\banana\\\\banana03.wav', '../ml_data/speeches/training\\\\banana\\\\banana04.wav', '../ml_data/speeches/training\\\\banana\\\\banana05.wav', '../ml_data/speeches/training\\\\banana\\\\banana06.wav', '../ml_data/speeches/training\\\\banana\\\\banana07.wav', '../ml_data/speeches/training\\\\banana\\\\banana08.wav', '../ml_data/speeches/training\\\\banana\\\\banana09.wav', '../ml_data/speeches/training\\\\banana\\\\banana10.wav', '../ml_data/speeches/training\\\\banana\\\\banana11.wav', '../ml_data/speeches/training\\\\banana\\\\banana12.wav', '../ml_data/speeches/training\\\\banana\\\\banana13.wav', '../ml_data/speeches/training\\\\banana\\\\banana14.wav'], 'kiwi': ['../ml_data/speeches/training\\\\kiwi\\\\kiwi01.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi02.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi03.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi04.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi05.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi06.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi07.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi08.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi09.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi10.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi11.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi12.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi13.wav', '../ml_data/speeches/training\\\\kiwi\\\\kiwi14.wav'], 'lime': ['../ml_data/speeches/training\\\\lime\\\\lime01.wav', '../ml_data/speeches/training\\\\lime\\\\lime02.wav', '../ml_data/speeches/training\\\\lime\\\\lime03.wav', '../ml_data/speeches/training\\\\lime\\\\lime04.wav', '../ml_data/speeches/training\\\\lime\\\\lime05.wav', '../ml_data/speeches/training\\\\lime\\\\lime06.wav', '../ml_data/speeches/training\\\\lime\\\\lime07.wav', '../ml_data/speeches/training\\\\lime\\\\lime08.wav', '../ml_data/speeches/training\\\\lime\\\\lime09.wav', '../ml_data/speeches/training\\\\lime\\\\lime10.wav', '../ml_data/speeches/training\\\\lime\\\\lime11.wav', '../ml_data/speeches/training\\\\lime\\\\lime12.wav', '../ml_data/speeches/training\\\\lime\\\\lime13.wav', '../ml_data/speeches/training\\\\lime\\\\lime14.wav'], 'orange': ['../ml_data/speeches/training\\\\orange\\\\orange01.wav', '../ml_data/speeches/training\\\\orange\\\\orange02.wav', '../ml_data/speeches/training\\\\orange\\\\orange03.wav', '../ml_data/speeches/training\\\\orange\\\\orange04.wav', '../ml_data/speeches/training\\\\orange\\\\orange05.wav', '../ml_data/speeches/training\\\\orange\\\\orange06.wav', '../ml_data/speeches/training\\\\orange\\\\orange07.wav', '../ml_data/speeches/training\\\\orange\\\\orange08.wav', '../ml_data/speeches/training\\\\orange\\\\orange09.wav', '../ml_data/speeches/training\\\\orange\\\\orange10.wav', '../ml_data/speeches/training\\\\orange\\\\orange11.wav', '../ml_data/speeches/training\\\\orange\\\\orange12.wav', '../ml_data/speeches/training\\\\orange\\\\orange13.wav', '../ml_data/speeches/training\\\\orange\\\\orange14.wav'], 'peach': ['../ml_data/speeches/training\\\\peach\\\\peach01.wav', '../ml_data/speeches/training\\\\peach\\\\peach02.wav', '../ml_data/speeches/training\\\\peach\\\\peach03.wav', '../ml_data/speeches/training\\\\peach\\\\peach04.wav', '../ml_data/speeches/training\\\\peach\\\\peach05.wav', '../ml_data/speeches/training\\\\peach\\\\peach06.wav', '../ml_data/speeches/training\\\\peach\\\\peach07.wav', '../ml_data/speeches/training\\\\peach\\\\peach08.wav', '../ml_data/speeches/training\\\\peach\\\\peach09.wav', '../ml_data/speeches/training\\\\peach\\\\peach10.wav', '../ml_data/speeches/training\\\\peach\\\\peach11.wav', '../ml_data/speeches/training\\\\peach\\\\peach12.wav', '../ml_data/speeches/training\\\\peach\\\\peach13.wav', '../ml_data/speeches/training\\\\peach\\\\peach14.wav'], 'pineapple': ['../ml_data/speeches/training\\\\pineapple\\\\pineapple01.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple02.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple03.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple04.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple05.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple06.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple07.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple08.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple09.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple10.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple11.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple12.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple13.wav', '../ml_data/speeches/training\\\\pineapple\\\\pineapple14.wav']}\n"
     ]
    }
   ],
   "source": [
    "#语音识别\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import python_speech_features as sf\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as sm\n",
    "import os\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "#检索directory目录下的所有文件，返回目录字典\n",
    "def search_files(directory):\n",
    "    objects={}\n",
    "    for curdir,subdirs,files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                label=curdir.split(os.path.sep)[-1]  #curdir当前目录\n",
    "                if label not in objects:\n",
    "                    objects[label]=[]\n",
    "                url=os.path.join(curdir,file)\n",
    "                objects[label].append(url)\n",
    "    return objects            \n",
    "train_urls=search_files('../ml_data/speeches/training')\n",
    "print(train_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 13) (98,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        14\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#整理训练集的输入与输出，训练svm模型\n",
    "train_x,train_y=[],[]\n",
    "for label,urls in train_urls.items():\n",
    "    for file in urls:\n",
    "        sample_rate,sigs=wf.read(file)\n",
    "        mfcc=sf.mfcc(sigs,sample_rate)\n",
    "        #把mfcc矩阵整理成（1，13）的样本\n",
    "        sample=np.mean(mfcc,axis=0)\n",
    "        train_x.append(sample)\n",
    "        train_y.append(label)\n",
    "train_x=np.array(train_x)    \n",
    "\n",
    "encoder=sp.LabelEncoder()\n",
    "train_y_label=encoder.fit_transform(train_y)\n",
    "print(train_x.shape,train_y_label.shape)\n",
    "\n",
    "#训练svm \n",
    "model=svm.SVC(kernel='poly',degree=2)\n",
    "model.fit(train_x,train_y_label)\n",
    "pred_train_y=model.predict(train_x)\n",
    "print(sm.classification_report(train_y_label,pred_train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, 13) (98,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        14\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        14\n",
      "           4       1.00      1.00      1.00        14\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#语音识别\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import python_speech_features as sf\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as sm\n",
    "import os\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "#检索directory目录下的所有文件，返回目录字典\n",
    "def search_files(directory):\n",
    "    objects={}\n",
    "    for curdir,subdirs,files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                label=curdir.split(os.path.sep)[-1]  #curdir当前目录\n",
    "                if label not in objects:\n",
    "                    objects[label]=[]\n",
    "                url=os.path.join(curdir,file)\n",
    "                objects[label].append(url)\n",
    "    return objects            \n",
    "test_urls=search_files('../ml_data/speeches/training')\n",
    "#整理训练集的输入与输出，训练svm模型\n",
    "test_x,test_y=[],[]\n",
    "for label,urls in test_urls.items():\n",
    "    for file in urls:\n",
    "        sample_rate,sigs=wf.read(file)\n",
    "        mfcc=sf.mfcc(sigs,sample_rate)\n",
    "        #把mfcc矩阵整理成（1，13）的样本\n",
    "        sample=np.mean(mfcc,axis=0)\n",
    "        test_x.append(sample)\n",
    "        test_y.append(label)\n",
    "test_x=np.array(test_x)    \n",
    "\n",
    "encoder=sp.LabelEncoder()\n",
    "test_y_label=encoder.fit_transform(test_y)\n",
    "print(train_x.shape,train_y_label.shape)\n",
    "\n",
    "#训练svm \n",
    "import sklearn.linear_model as lm\n",
    "model=lm.LogisticRegression()\n",
    "model=svm.SVC(kernel='poly',degree=2,probability=True)\n",
    "model.fit(test_x,test_y_label)\n",
    "pred_test_y=model.predict(test_x)\n",
    "print(sm.classification_report(train_y_label,pred_train_y))\n",
    "\n",
    "#比较测试集输出和真实输出\n",
    "print(sm.classification_report(test_y_label,pred_test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 0.858405347069955\n",
      "apple 0.8030044605173204\n",
      "apple 0.8753660576965632\n",
      "apple 0.8738030669839307\n",
      "apple 0.6743762240697256\n",
      "apple 0.8483175756530071\n",
      "apple 0.9176982131939757\n",
      "apple 0.7728121676566737\n",
      "apple 0.6688632203799381\n",
      "apple 0.842037509374379\n",
      "apple 0.8142120078396158\n",
      "apple 0.8545272100730034\n",
      "apple 0.8206097511655419\n",
      "apple 0.6110550581725114\n",
      "banana 0.7860395688345952\n",
      "banana 0.7932634611149597\n",
      "banana 0.6827622692470012\n",
      "banana 0.8880364077544988\n",
      "banana 0.8095063572612399\n",
      "banana 0.7758470913309354\n",
      "banana 0.6739459899763224\n",
      "banana 0.7706766309997595\n",
      "banana 0.8292711330982961\n",
      "banana 0.9026175255507314\n",
      "banana 0.9343831986927342\n",
      "banana 0.8614797764074086\n",
      "banana 0.8384628047054666\n",
      "banana 0.8251941484731856\n",
      "kiwi 0.7036304487617204\n",
      "kiwi 0.6121034375195085\n",
      "kiwi 0.7658707686254094\n",
      "kiwi 0.8919040354090542\n",
      "kiwi 0.839888469215136\n",
      "kiwi 0.7320103730396642\n",
      "kiwi 0.840608004966551\n",
      "kiwi 0.8649027771599923\n",
      "kiwi 0.8751523679647463\n",
      "kiwi 0.833700985535955\n",
      "kiwi 0.8538688406512444\n",
      "kiwi 0.6917642227633404\n",
      "kiwi 0.8703929320088966\n",
      "kiwi 0.8341319404404571\n",
      "lime 0.6218352833112624\n",
      "lime 0.7600534261737765\n",
      "lime 0.8131415525544159\n",
      "lime 0.7904695804991515\n",
      "lime 0.8232165100144703\n",
      "lime 0.8515720683554606\n",
      "lime 0.7683125438079647\n",
      "lime 0.8321488936118197\n",
      "lime 0.8138163461178705\n",
      "lime 0.8170126166811938\n",
      "lime 0.663526229884905\n",
      "lime 0.7023350352345713\n",
      "lime 0.8432927584721345\n",
      "lime 0.8403802488342578\n",
      "orange 0.6428574331149093\n",
      "orange 0.7401953130725787\n",
      "orange 0.7364865772997917\n",
      "orange 0.76697456472787\n",
      "orange 0.7607525158333639\n",
      "orange 0.7709111273254917\n",
      "orange 0.7973292757385763\n",
      "orange 0.7838297671714416\n",
      "orange 0.7766949603109561\n",
      "orange 0.7272556778774718\n",
      "orange 0.7472803005430106\n",
      "orange 0.7342209306347051\n",
      "orange 0.7708577371367664\n",
      "orange 0.7675326771495163\n",
      "peach 0.7293556833286635\n",
      "peach 0.734675662847525\n",
      "peach 0.7090186476243692\n",
      "peach 0.7910842232124055\n",
      "peach 0.8250930695946838\n",
      "peach 0.7794628426779404\n",
      "peach 0.8278771676271988\n",
      "peach 0.817249417326739\n",
      "peach 0.8333597519085304\n",
      "peach 0.8208591556955245\n",
      "peach 0.80084877400448\n",
      "peach 0.807526385038222\n",
      "peach 0.7580311860994201\n",
      "peach 0.8135506445221894\n",
      "pineapple 0.8607699916953243\n",
      "pineapple 0.7989040976666034\n",
      "pineapple 0.8782852822243633\n",
      "pineapple 0.9030173975136712\n",
      "pineapple 0.8914617969072879\n",
      "pineapple 0.7371485033686391\n",
      "pineapple 0.8055882695764661\n",
      "pineapple 0.7970211691617487\n",
      "pineapple 0.8295053168698556\n",
      "pineapple 0.8398124803691815\n",
      "pineapple 0.7871978848691272\n",
      "pineapple 0.6043192103945605\n",
      "pineapple 0.7324943232006886\n",
      "pineapple 0.6936991607261341\n"
     ]
    }
   ],
   "source": [
    "#置信概率\n",
    "probs=model.predict_proba(test_x)\n",
    "for label,prob in zip(\n",
    "        #将标准化后的数据转换为原始数据\n",
    "        encoder.inverse_transform(pred_test_y),  \n",
    "        probs.max(axis=1)):\n",
    "    print(label,prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
